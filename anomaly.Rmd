---
title: "Cross anomalies"
output: html_document
---
The code aims at creating cross-validated anomalies from data produced by "extraction"
It requires data extracted by "extraction"

```{r setup, include=FALSE}

library(easyVerification)
library(verification)
library(dplyr)
library(plyr)
library(foreach)
library(iterators)
library(parallel)
library(doParallel)

```

## Parameters 

Some are loaded (because they remain permanent through codes)
Some are set here and can therefore be modified by user

```{r }

                                     ### SELECTED PARAMETERS (to be set by user) ###

# selected project and directories
selected_project <- "stics" # stics or season or tree
dir_data <- paste0("D:/HOME/ekamir/scoring_medscope/data/",selected_project) 
dir_plot <- "D:/HOME/ekamir/scoring_medscope/figure" 

# number of cores
no_core <- 6


                                      ### LOADED PARAMETERS (permanent) ###


# loading number of bootstrap interations
load(file = file.path(dir_data, "extract", "nboot.RData"))

# loading variables
load(file = file.path(dir_data, "extract", "indicateurs.RData"))
# loading time scales and agregation type
load(file = file.path(dir_data, "extract", "temporalite.RData")) # is there a time dimension
load(file = file.path(dir_data, "extract", "time_window.RData")) # if yes which window is selected
load(file = file.path(dir_data, "extract", "agregation.RData")) # if yes what type of aggregation should be applied

ntemp <- length(temp) # number of elements in time dimension

# loading ensemble members
load(file = file.path(dir_data, "extract", "runs.RData"))
nrun <- length(run) # number of members

# loading years
load(file = file.path(dir_data, "extract", "years.RData"))
nan <- length(an) # number of years

```

## Loading files

We load values extracted in "extraction" and compute their cross validated anomalies, for reference and ps only

```{r, echo=FALSE}

  tictoc::tic() # timer

for (indicateur in indicateurs){
  
  d <- which(indicateurs==indicateur)
  temporalite <- time_scale[d] # select corresponding time dimension: single or multi
  agreg <- agreg_type[d] # select corresponding time aggregation type: sum or mean

 # parallelizing extraction on bootstrap iterations
    
cl <- makeCluster(no_core) # setting up number of cores
registerDoParallel(cl) # parallelizing on them

foreach(b=1:nboot, .packages="tidyverse") %dopar%  { # for-loop parallelized
  
  # loading reference and ps data
  nom_ref <- paste0(indicateur,b,"_ref_uerra5.RData")
  nom_prev <- paste0(indicateur,b,"_prev_uerra5.RData")

  load(file = file.path(dir_data, "extract", nom_ref))
  load(file = file.path(dir_data, "extract", nom_prev))

  ngrids <- dim(array_obs)[1] # trick to automatically get number of grids

  
  # time aggregation if the time dimension is "multi" 
  
  if (temporalite=="single"){ # in that case we keep original data
  prev_seas <- array_prev 
  ref_seas <- array_obs
  } else if (temporalite=="multi") { # in that case we aggregate using pre defined function specific to each variable
    if (agreg=="sum"){
    prev_seas <- apply(array_prev[,,,temp], c(1,2,3), sum) 
    ref_seas <- apply(array_obs[,,temp], c(1,2), sum)
    } else if (agreg=="mean"){
    prev_seas <- apply(array_prev[,,,temp], c(1,2,3), mean) 
    ref_seas <- apply(array_obs[,,temp], c(1,2), mean)
    }
    
  }
  
  # setting up arrays for data to be stored in
  prev_anomaly <- array(NA,dim=c(ngrids,nan,nrun))
  obs_anomaly <- array(NA,dim=c(ngrids,nan))

  for (y in 1:nan){ # each year we compute crossed mean (excluding ongoing year) and compute the difference with ongoing year value
    cv_mean_prev <- apply(prev_seas[,-y,], c(1,3), mean)
    cv_mean_obs <- apply(ref_seas[,-y], 1, mean)

    prev_anomaly[,y,] <- prev_seas[,y,]-cv_mean_prev
    obs_anomaly[,y] <- ref_seas[,y]-cv_mean_obs
    
  }
  
  # file naming 
  nom_prev <- paste0(indicateur,b,"_anomaly_prev_uerra5.RData")
  nom_obs <- paste0(indicateur,b,"_anomaly_obs_uerra5.RData")
  
  # file saving 
  save(prev_anomaly, file = file.path(dir_data, "extract", nom_prev))
  save(obs_anomaly, file = file.path(dir_data, "extract", nom_obs))
  
}
stopCluster(cl) # stop parallelizing

}

tictoc::toc() # stop timer

```
