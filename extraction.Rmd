---
title: "data_extraction"
output: html_document
---
The code aims at reshaping data in useful way for further treatments
Data is loaded from original csv files, and stored in mutlidimensional arrays. One array is created for each variable, each climat type (ref, ps or climato), and each bootstrap iteration. 

Array dimension:
- reference: grids.years(.time_dimension)
- prevision/clim: grids.years.members(.time_dimension)

```{r setup, include=FALSE, echo=FALSE}

library(dplyr)
library(plyr)
library(tidyverse)
library(foreach)
library(iterators)
library(parallel)
library(doParallel)
library(tictoc)


```

## Parameters 

To be set by user

```{r }

                                               ###### PARAMETERS ######

# selecting project
selected_project <- "tree" # stics or season or tree
# directories and cores
setup(project = selected_project, no_cores = 6)

# number of cores
no_core <- 6

                                               ###### METADATA ######

# number of bootstrap iterations
nboot <- 100
save(nboot, file = file.path(dir_data, "extract", "nboot.RData"))


# variables and time scales: always modify all at once
if (selected_project=="stics"){
  indicateurs <- c("drainall", "etall", "yieldwheat", "yieldgrass")
  time_scale <- c("multi", "multi", "single", "single") #wether there is a time dimension or not
  temp <- 9:20 # time window selected, in case of "multi, scale is fortnight here (9:20 --> may - october)
  agreg_type <- c("sum","sum","none", "none","none") # type of aggregation over time dimension in case of "multi"

}else if (selected_project=="season"){
  indicateurs <- c("drain", "draindef", "dtmax35", "dtmax40", "dtmoy25","drywav", "heatwav") 
  time_scale <- c("multi", "multi", "multi", "multi", "multi","single","single")
  temp <- 1:6 # length of agregation
  agreg_type <- c("sum","sum","sum", "sum","sum","none","none")

}else if (selected_project=="tree"){
  indicateurs <- c("nsc", "plc", "ringwidth", "fwi90", "fot30", "mean_fwi")#"min_lfmc"
  time_scale <- c("single", "single", "single", "single", "single", "single")
  temp <- 9:20 # length of agregation
  agreg_type <- 0
}

save(indicateurs, file = file.path(dir_data, "extract", "indicateurs.RData"))
save(time_scale, file = file.path(dir_data, "extract", "temporalite.RData"))
save(temp, file = file.path(dir_data, "extract", "time_window.RData"))
save(agreg_type, file = file.path(dir_data, "extract", "agregation.RData"))

# ensemble members (or runs)
run <- seq(from=1, to=25, by=1) # runs
nrun <- length(run) # number of runs
save(run, file = file.path(dir_data, "extract", "runs.RData"))

# years
an <- seq(1993,2016,1) # year sequence
nan <- length(an) # number of years
save(an, file = file.path(dir_data, "extract", "years.RData"))

```

## Loading data in csv file

Data is loaded from csv extracts which are specific to each project
Time scale filtering is applied on some indicators that have more than one time dimension type

```{r data loading, echo=FALSE}

raws <- list()

if (selected_project=="stics"){
  
  raws[[1]] <- read.csv(file = file.path(dir_data, "Extract_STICS-KCETP_DRAIN_ALL_P05_crau45_1993_2016.csv"), header = TRUE, sep = ",")
  raws[[2]] <- read.csv(file = file.path(dir_data, "Extract_STICS-KCETP_ET_ALL_P05_crau45_1993_2016.csv"), header = TRUE, sep = ",")
  raws[[3]] <- read.csv(file = file.path(dir_data, "Extract_STICS-KCETP_RENDEMENT_WHEAT_P05_crau45_1993_2016.csv"), header = TRUE, sep = ",")
  raws[[4]] <- read.csv(file = file.path(dir_data, "Extract_STICS-KCETP_RENDEMENT_GRASS_P05_crau45_1993_2016.csv"), header = TRUE, sep = ",") 
  raws[[4]] <- raws[[4]] %>% filter(period == "ANNEE")
  

}else if (selected_project=="season"){

  raws[[1]] <- read.csv(file = file.path(dir_data, "P05_SEASON_1993_2016_d_rain.csv"), header = TRUE, sep = ",")
  raws[[2]] <- read.csv(file = file.path(dir_data, "P05_SEASON_1993_2016_d_raindef.csv"), header = TRUE, sep = ",")
  raws[[3]] <- read.csv(file = file.path(dir_data, "P05_SEASON_1993_2016_d_tmax_35.csv"), header = TRUE, sep = ",")
  raws[[4]] <- read.csv(file = file.path(dir_data, "P05_SEASON_1993_2016_d_tmax_40.csv"), header = TRUE, sep = ",")
  raws[[5]] <- read.csv(file = file.path(dir_data, "P05_SEASON_1993_2016_d_tmoy_25.csv"), header = TRUE, sep = ",")
  raws[[6]] <- read.csv(file = file.path(dir_data, "P05_SEASON_1993_2016_dry_wave.csv"), header = TRUE, sep = ",") 
  raws[[6]] <- raws[[6]] %>% filter(period_ == "SEASONAL")
  raws[[7]] <- read.csv(file = file.path(dir_data, "P05_SEASON_1993_2016_heat_wave.csv"), header = TRUE, sep = ",") 
  raws[[7]] <- raws[[7]] %>% filter(period_ == "SEASONAL")

  
}else if (selected_project=="tree"){

                                        # CASTANEA #

raws[[1]] <- read.csv(file = file.path(dir_data,"P05_CASTANEA", "P05_CASTANEA_NSC.csv"), header = TRUE, sep = ",") 
raws[[1]] <- raws[[1]] %>% filter(specie_levelofstones == "FAGUS_SYLVATICA_0.55")
raws[[2]] <- read.csv(file = file.path(dir_data,"P05_CASTANEA", "P05_CASTANEA_PLC.csv"), header = TRUE, sep = ",") 
raws[[2]] <- raws[[2]] %>% filter(specie_levelofstones == "FAGUS_SYLVATICA_0.55")
raws[[3]] <- read.csv(file = file.path(dir_data,"P05_CASTANEA", "P05_CASTANEA_RingWidth.csv"), header = TRUE, sep = ",") 
raws[[3]] <- raws[[3]] %>% filter(specie_levelofstones == "FAGUS_SYLVATICA_0.55")

                                          # FWI #

raws[[4]] <- read.csv(file = file.path(dir_data,"P05_FWI", "P05_FWI_FWI90.csv"), header = TRUE, sep = ",")
raws[[5]] <- read.csv(file = file.path(dir_data,"P05_FWI", "P05_FWI_FOT30.csv"), header = TRUE, sep = ",")
raws[[6]] <- read.csv(file = file.path(dir_data,"P05_FWI", "P05_FWI_MEANFWI.csv"), header = TRUE, sep = ",")
raws[[6]] <- raws[[6]] %>% filter(period == "SEASONAL")

                                          # SUREAU #

raws[[7]] <- read.csv(file = file.path(dir_data,"P05_SUREAU", "P05_SUREAU_MINMC_FAGUS.csv"), header = TRUE, sep = ",") 
raws[[7]] <- raws[[7]] %>% filter(!period == "YEAR")

}

```


## Reshaping data

For each indicator, each climate type (reference, prevision, climatology), values are stored in multi-dimensional arrays:  
Reference array has 3 dimension: grid+year+time
Prevision/climatology arrays have 4 dimensions: grid+year+run+time

```{r, echo=FALSE}

# generating random year series: should be generated once because it hase to remain the same through all codes
#rand_year <- list()
# for (b in 1:nboot){
#    rand_year[[b]] <- sample(an, nan, replace = TRUE) # attention version Elisa ne generait pas les n° d'année
#  }
#  save(rand_year, file = file.path(dir_data, "extract",  "rand_years.RData"))

load(file = file.path(dir_data, "extract", "rand_years.RData")) # loading list of bootstrapped years 


tictoc::tic() # timer

for (indicateur in indicateurs) {
  
  d <- which(indicateurs==indicateur)
  data <- raws[[d]] # select corresponding csv from previous list
  temporalite <- time_scale[d] # select corresponding time dimension: single or multi
  
  
  
                                               ### COORDINATES ###
  


  # longitudes
raw_filtered <- data %>% select(cellnum,lon,lat) %>% distinct(cellnum, .keep_all= TRUE) # using distinct we only keep unique cellnums 
lon <- raw_filtered %>% select(lon)
lon <- as.numeric(unlist(lon))

save(lon, file = file.path(dir_data, "extract", paste0(indicateur, "_lon.RData")))

  # latitudes
lat <- raw_filtered %>% select(lat)
lat <- as.numeric(unlist(lat))

save(lat, file = file.path(dir_data, "extract", paste0(indicateur, "_lat.RData")))


                                               ### LAUNCHING EXTRACTION ###


  # number of grids
ngrids <- length(lat)

 # climat type filtering
    obs_data <- data %>% 
      filter(climattype == "REF") 
    
    prev_data <- data %>% 
      filter(climattype == "PS") 
    
    clim_data <- data %>% 
      filter(climattype == "CLIMATO") 

 # parallelizing extraction on bootstrap iterations
    
cl <- makeCluster(no_core) # setting up number of cores
registerDoParallel(cl) # parallelizing on them

foreach(b=1:nboot, .packages=c("tidyverse", "dplyr")) %dopar%  { # for-loop parallelized
  
      
                                      ### EXTRACTING VARIABLES WITHOUT TIME DIMENSION ###
      
  if (temporalite=="single"){
    
    # creating arrays for data to be stored in
    array_obs <- array(NA, dim=c(ngrids, nan)) 
    array_prev <- array(NA, dim=c(ngrids, nan, nrun))
    array_clim <- array(NA, dim=c(ngrids, nan, nrun))

    for (j in 1:nan){
      y <- rand_year[[b]][j] # we pick a year from the randomize serie
      
      # at first we filter on year
      obs_int <- obs_data %>% 
      filter(year_ == y) 
      prev_int1 <- prev_data %>% 
      filter(year_ == y) 
      clim_int1 <- clim_data %>% 
      filter(year_ == y) 

      # filling up reference array
        array_obs[,j] <- as.vector(unlist(obs_int %>% arrange(cellnum) %>% select(indicatorvalue))) 
 
      # filling up clim and ps arrays requires run filtering 
        for (r in 1:nrun){
        array_prev[,j,r] <- as.vector(unlist(prev_int1 %>% filter(climatscenario == r) %>% arrange(cellnum) %>% select(indicatorvalue)))
        array_clim[,j,r] <- as.vector(unlist(clim_int1 %>% filter(climatscenario == r) %>% arrange(cellnum) %>% select(indicatorvalue)))
        }

    }
    
  
                                      ### EXTRACTING VARIABLES WITH TIME DIMENSION ###
    
    

  } else if (temporalite=="multi") { 
    
      # homogenizing time dimension column name  
      if (selected_project=="season"){
        colnames(obs_data)[which(colnames(obs_data)=='month_')] <- "period"
        colnames(prev_data)[which(colnames(prev_data)=='month_')] <- "period"
        colnames(clim_data)[which(colnames(clim_data)=='month_')] <- "period"
      }
    
    # we extract temporal dimensions
    dimT <- unique(obs_data[,"period"])
    ndimT <- length(dimT)
    
    # creating arrays for data to be stored in
    array_obs <- array(NA, dim=c(ngrids, nan, ndimT)) 
    array_prev <- array(NA, dim=c(ngrids, nan, nrun, ndimT))
    array_clim <- array(NA, dim=c(ngrids, nan, nrun, ndimT))

    for (j in 1:nan){
      y <- rand_year[[b]][j] # we pick a year from the randomize serie
      
      # at first we filter on year
      obs_int <- obs_data %>% 
      filter(year_ == y)
      prev_int1 <- prev_data %>% 
      filter(year_ == y) 
      clim_int1 <- clim_data %>% 
      filter(year_ == y) 


      # then we filter on time dimension (within a year)
      for (t in c(1:ndimT)){  
        
              # filling up reference array
        array_obs[,j,t] <- as.vector(unlist(obs_int %>% filter(period == dimT[t]) %>% arrange(cellnum) %>% select(indicatorvalue))) 
        
        prev_int2 <- prev_int1 %>% 
        filter(period == dimT[t])  
        clim_int2 <- clim_int1 %>% 
        filter(period == dimT[t])  
 
      # filling up clim and ps arrays also requires run filtering 
        for (r in 1:nrun){
        array_prev[,j,r,t] <- as.vector(unlist(prev_int2 %>% filter(climatscenario == r) %>% arrange(cellnum) %>% select(indicatorvalue)))
        array_clim[,j,r,t] <- as.vector(unlist(clim_int2 %>% filter(climatscenario == r) %>% arrange(cellnum) %>% select(indicatorvalue)))
        }
      }
    }
      
    }
  
    # file naming 
    nom_ref <- paste0(indicateur,b,"_ref_uerra5.RData")
    nom_prev <- paste0(indicateur,b,"_prev_uerra5.RData")
    nom_clim <- paste0(indicateur,b,"_clim_uerra5.RData")
    
    # saving data
    save(array_obs, file = file.path(dir_data, "extract", nom_ref))
    save(array_prev, file = file.path(dir_data, "extract", nom_prev))
    save(array_clim, file = file.path(dir_data, "extract", nom_clim))
  }
  
} 

stopCluster(cl) # stop parallelizing


tictoc::toc() # stop timer

```
